from io import BytesIO
from subprocess import Popen, PIPE
import tempfile

import re
from healthcheck import HealthCheck, EnvironmentDump
import time
import os
import requests
from flask import Flask, send_file, request, Response
from werkzeug.contrib.cache import SimpleCache
# import ga4gh_tool_registry.validate as validate
import urllib
import createProcessedYAML
from badge import passing_badge, failing_badge, warning_badge, error_badge
from constants import SWAGGER, EXPECTED_PASSING_TESTS, GITHUB_BASEURL, GITHUB_BRANCH, GITHUB_FILE_PATH

app = Flask(__name__)

health = HealthCheck(app, "/health_check")
envdump = EnvironmentDump(app, "/environment")
cache = SimpleCache()


def _compute_badge(url):
    # (out, err) = validate(url)
    # if "Failed to establish a new connection" in err:
    #     return error_badge()
    # if err != 'API returned valid response\n':
    #     return failing_badge()
    # else:
    """

    :param url: The url the validator is testing
    :return: A badge determined by the test status
    """
    out2 = _get_dredd_log(url)
    return _badge_from_output(out2)


def _get_dredd_log(url):
    """
    This gets the Dredd validation output.
    This can be either a new Dredd validation run or an old one.
    :param url: The url to test
    :return: The Dredd validation output
    """
    file_url = re.sub(r'[^\w]', '', url.encode('utf8'))
    # if there is a log file and it was created in the last 5 mins (300 seconds)
    # TODO: Explore the possibility of removing this.  Apparently GitHub
    # caches it by default
    if os.path.isfile(file_url) and time.time() - \
            os.path.getmtime(file_url) < 300:
        out2 = _filename_to_string(file_url)
    else:
        out2 = run_dredd(SWAGGER, url)
        with open(file_url, 'w+') as warning_yaml_file:
            warning_yaml_file.write(out2)
    return out2


def _badge_from_output(output):
    """
    Determines which badge should be returned based on validation output
    :param output: Output from validation
    :return: Badge based on validation output
    """
    if ' 0 errors' not in output:
        badge = cache.get('error')
        if badge is None:
            badge = requests.get(error_badge())
            cache.set('error', badge, timeout=5*60)
        return badge
    if ' 0 failing' not in output:
        badge = cache.get('failing')
        if badge is None:
            badge = requests.get(failing_badge())
            cache.set('failing', badge, timeout=5 * 60)
        return badge
    if str(EXPECTED_PASSING_TESTS) + ' passing' not in output:
        badge = cache.get('warning')
        if badge is None:
            badge = requests.get(warning_badge())
            cache.set('warning', badge, timeout=5 * 60)
        return badge
    if ' 0 failing, 0 errors' in output:
        badge = cache.get('passing')
        if badge is None:
            badge = requests.get(passing_badge())
            cache.set('passing', badge, timeout=5 * 60)
        return badge


@app.route('/trs/validator', methods=['GET'])
def status_badge():
    """
    Endpoint that returns status badge
    :return: Status badge
    """
    url = request.args.get('url', '')
    badge_response = _compute_badge(url)
    return send_file(BytesIO(badge_response.content), mimetype=badge_response.headers['Content-Type'])


@app.route('/trs/validator/debug', methods=['GET'])
def debug():
    """
    Endpoint that returns the log file from validation
    :return:
    """
    url = request.args.get('url', '')
    r = _get_dredd_log(url)
    response = Response(r, mimetype="text/plain")
    return response


def validate(url):
    # validate.validate('ga4gh-tool-discovery.yaml', 'annotations.yml', url, False, False, False)
    """
    Validates against the original validation code.  Currently not in use.
    :param url: The url to test validation against
    :return: The output
    """
    file_directory = os.path.dirname(__file__)
    swagger_file_path = os.path.join(file_directory, SWAGGER)
    command_args = [
        'ga4gh-tool-registry-validate',
        swagger_file_path,
        'annotations.yml',
        url + '/tools']
    process = Popen(command_args, stdout=PIPE, stderr=PIPE)
    return process.communicate()


def run_dredd(swagger_filename, url):
    """
    This runs Dredd against the url and given swagger yaml file
    :param swagger_filename: The swagger yaml to test against
    :param url: The url of the webservice to test
    :return: Output generated by Dredd
    """
    file_directory = os.path.dirname(__file__)
    swagger_file_path = os.path.join(file_directory, swagger_filename)
    hooks_file_path = os.path.join(file_directory, 'hooks.py')
    command_args = [
        'dredd',
        swagger_file_path,
        url,
        '-l',
        'fail',
        '-c',
        'false',
        '-a',
        'python',
        '-f',
        hooks_file_path]
    outfile = tempfile.NamedTemporaryFile('w')
    process = Popen(command_args, stdout=outfile, stderr=PIPE)
    process.wait()
    return _filename_to_string(outfile.name)


@app.after_request
def add_header(response):
    response.cache_control.max_age = 300
    return response


def _filename_to_string(filename):
    """
    The output was written to a temporary file because the output is too large for the buffer.
    This converts the file contents back to a string
    :param filename: The name of the file containing the Dredd output
    :return: String containing the file contents
    """
    with open(filename) as f:
        return f.read()


def _download_swagger_yaml():
    """
    Downloads the swagger yaml from ga4gh tool-registry-schemas
    TODO: Change the GitHub path once the TRSV changes are merged
    """
    file_directory = os.path.dirname(__file__)
    swagger_file_path = os.path.join(
        file_directory, "ga4gh-tool-discovery.yaml")
    urllib.urlretrieve(
        GITHUB_BASEURL + "/" + GITHUB_BRANCH + "/" + GITHUB_FILE_PATH,
        swagger_file_path)


if __name__ == '__main__':
    _download_swagger_yaml()
    createProcessedYAML.main()
    app.run(host='0.0.0.0', port=8080)
